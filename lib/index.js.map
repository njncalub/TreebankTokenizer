{
  "version": 3,
  "sources": ["../src/utils.ts", "../src/index.ts"],
  "sourcesContent": ["/**\n * This function attemps to find the offsets of the tokens in sentence, as\n * a sequence of `[start, end]` arrays, given the tokens and also the source\n * string.\n *\n * @param tokens array of strings that are the result of the tokenization\n * @param sentence the original string\n * @returns array of [start, end] points of tokens\n */\nexport function align_tokens(\n  tokens: string[],\n  sentence: string\n): [number, number][] {\n  let point = 0;\n  let offsets: [number, number][] = [];\n  let start: number;\n\n  for (let token of tokens) {\n    start = sentence.indexOf(token, point);\n    if (start === -1) {\n      throw Error(`substring ${token} not found in \"${sentence}\"`);\n    }\n    point = start + token.length;\n    offsets.push([start, point]);\n  }\n\n  return offsets;\n}\n", "// @ts-check\nimport { align_tokens } from \"./utils\";\n\nclass MacIntyreContractions {\n  CONTRACTIONS2 = [\n    /\\b(can)(not)\\b/,\n    /\\b(d)('ye)\\b/,\n    /\\b(gim)(me)\\b/,\n    /\\b(gon)(na)\\b/,\n    /\\b(got)(ta)\\b/,\n    /\\b(lem)(me)\\b/,\n    /\\b(more)('n)\\b/,\n    /\\b(wan)(na)(?=s)/,\n  ];\n  CONTRACTIONS3 = [/ ('t)(is)\\b/, / ('t)(was)\\b/];\n  CONTRACTIONS4 = [/\\b(whad)(dd)(ya)\\b/, /\\b(wha)(t)(cha)\\b/];\n}\n\n/**\n *  Copied from NLTK Python documentation\n * \n    The Treebank tokenizer uses regular expressions to tokenize text as in Penn Treebank.\n\n    This tokenizer performs the following steps:\n\n    - split standard contractions, e.g. ``don't`` -> ``do n't`` and ``they'll`` -> ``they 'll``\n    - treat most punctuation characters as separate tokens\n    - split off commas and single quotes, when followed by whitespace\n    - separate periods that appear at the end of line\n\n    >>> from nltk.tokenize import TreebankWordTokenizer\n    >>> s = '''Good muffins cost $3.88\\nin New York.  Please buy me\\ntwo of them.\\nThanks.'''\n    >>> TreebankWordTokenizer().tokenize(s)\n    ['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York.', 'Please', 'buy', 'me', 'two', 'of', 'them.', 'Thanks', '.']\n    >>> s = \"They'll save and invest more.\"\n    >>> TreebankWordTokenizer().tokenize(s)\n    ['They', \"'ll\", 'save', 'and', 'invest', 'more', '.']\n    >>> s = \"hi, my name can't hello,\"\n    >>> TreebankWordTokenizer().tokenize(s)\n    ['hi', ',', 'my', 'name', 'ca', \"n't\", 'hello', ',']\n    \n */\nclass TreebankTokenizer {\n  readonly STARTING_QUOTES: [RegExp, string][] = [\n    [/^\\\"/, \"``\"],\n    [/(``)/, \" $1 \"],\n    [/([ \\(\\[{<])(\\\"|\\'{2})/, \"$1 `` \"],\n  ];\n\n  readonly PUNCTUATION: [RegExp, string][] = [\n    [/([:,])([^\\d])/g, \" $1 $2\"],\n    [/([:,])$/g, \" $1 \"],\n    [/\\.\\.\\./g, \" ... \"],\n    [/([;@#$%&])/g, \" $1 \"],\n    [/([^\\.])(\\.)([\\]\\)}>\\\"\\']*)\\s*$/, \"$1 $2$3 \"], // Handles the final period.\n    [/([?!])/g, \" $1 \"],\n    [/([^'])' /g, \"$1 ' \"],\n  ];\n\n  // Pads parentheses\n  readonly PARENS_BRACKETS: [RegExp, string] = [/([\\]\\[\\(\\){}<>])/g, \" $1 \"];\n\n  // Optionally: Convert parentheses, brackets and converts them to PTB symbols.\n  readonly CONVERT_PARENTHESES: [RegExp, string][] = [\n    [/\\(/, \"-LRB-\"],\n    [/\\)/, \"-RRB-\"],\n    [/\\[/, \"-LSB-\"],\n    [/\\]/, \"-RSB-\"],\n    [/{/, \"-LCB-\"],\n    [/}/, \"-RCB-\"],\n  ];\n\n  readonly DOUBLE_DASHES: [RegExp, string] = [/--/, \" -- \"];\n\n  // ending quotes\n  readonly ENDING_QUOTES: [RegExp, string][] = [\n    [/''/, \" '' \"],\n    [/\\\"/, \" '' \"],\n    [/([^' ])('[sS]|'[mM]|'[dD]|') /, \"$1 $2 \"],\n    [/([^' ])('ll|'LL|'re|'RE|'ve|'VE|n't|N'T) /, \"$1 $2 \"],\n  ];\n\n  // List of contractions adapted from Robert MacIntyre's tokenizer.\n  _contractions = new MacIntyreContractions();\n  CONTRACTIONS2 = this._contractions.CONTRACTIONS2.map(\n    (r) => new RegExp(r, \"i\")\n  );\n  CONTRACTIONS3 = this._contractions.CONTRACTIONS3.map(\n    (r) => new RegExp(r, \"i\")\n  );\n\n  /**\n   * Return a tokenized copy of `text`.\n   *\n   * @param text A string with a sentence or sentences\n   * @param convert_parantheses if true, replaces parantheses with PTB symbols,\n   * eg., `(` to `-LRB-`. Defaults to false.\n   * @returns List of tokens from `text`\n   */\n  tokenize(text: string, convert_parantheses: boolean = false): string[] {\n    for (let quote of this.STARTING_QUOTES) {\n      var [regexp, substitution] = [...quote];\n      text = text.replace(regexp, substitution);\n    }\n\n    for (let punc of this.PUNCTUATION) {\n      var [regexp, substitution] = [...punc];\n      text = text.replace(regexp, substitution);\n    }\n\n    // Handles parentheses.\n    var [regexp, substitution] = [...this.PARENS_BRACKETS];\n    text = text.replace(regexp, substitution);\n\n    // Optionally convert parentheses\n    if (convert_parantheses) {\n      for (let paran of this.CONVERT_PARENTHESES) {\n        var [regexp, substitution] = [...paran];\n        text = text.replace(regexp, substitution);\n      }\n    }\n\n    // Handles double dash\n    var [regexp, substitution] = [...this.DOUBLE_DASHES];\n    text = text.replace(regexp, substitution);\n\n    // add extra space to make things easier\n    text = \" \" + text + \" \";\n\n    for (let quote of this.ENDING_QUOTES) {\n      var [regexp, substitution] = [...quote];\n      text = text.replace(regexp, substitution);\n    }\n\n    for (let regexp of this.CONTRACTIONS2) {\n      text = text.replace(regexp, \" $1 $2 \");\n    }\n\n    for (let regexp of this.CONTRACTIONS3) {\n      text = text.replace(regexp, \" $1 $2 \");\n    }\n\n    return text.trim().split(/\\s+/);\n  }\n\n  span_tokenize(text: string): [number, number][] {\n    let rawTokens: string[] = this.tokenize(text);\n    let tokens: string[];\n\n    // Convert converted quotes back to original double quotes\n    // Do this only if original text contains double quote(s) or double\n    // single-quotes (because '' might be transformed to `` if it is\n    // treated as starting quotes).\n    if (text.includes('\"') || text.includes(\"''\")) {\n      // Find double quotes and converted quotes\n      let matched: string[] = [...text.matchAll(/``|'{2}|\\\"/g)].map(\n        (match) => match[0]\n      );\n      // Replace converted quotes back to double quotes\n      // tokens = [\n      //     matched.pop(0) if tok in [] else tok\n      //     for tok in raw_tokens\n      // ]\n      tokens = rawTokens.map((tok) =>\n        ['\"', \"``\", \"''\"].indexOf(tok) !== -1 ? matched.splice(0, 1)[0] : tok\n      );\n    } else {\n      tokens = rawTokens;\n    }\n\n    return align_tokens(tokens, text);\n  }\n\n  tokenize_sents(sentences) {\n    return sentences.map((s) => this.tokenize(s));\n  }\n\n  *span_tokenize_sents(sentences) {\n    for (let s of sentences) {\n      yield this.span_tokenize(s);\n    }\n  }\n}\n\nmodule.exports = TreebankTokenizer;\n"],
  "mappings": "AASO,WACL,EACA,EACoB,CACpB,GAAI,GAAQ,EACR,EAA8B,GAC9B,EAEJ,OAAS,KAAS,GAAQ,CAExB,GADA,EAAQ,EAAS,QAAQ,EAAO,GAC5B,IAAU,GACZ,KAAM,OAAM,aAAa,mBAAuB,MAElD,EAAQ,EAAQ,EAAM,OACtB,EAAQ,KAAK,CAAC,EAAO,IAGvB,MAAO,GCvBT,WAA4B,CAA5B,aAHA,CAIE,mBAAgB,CACd,iBACA,eACA,gBACA,gBACA,gBACA,gBACA,iBACA,oBAEF,mBAAgB,CAAC,cAAe,gBAChC,mBAAgB,CAAC,qBAAsB,uBA2BzC,OAAwB,CAAxB,aA1CA,CA2CW,qBAAsC,CAC7C,CAAC,MAAO,MACR,CAAC,OAAQ,QACT,CAAC,wBAAyB,WAGnB,iBAAkC,CACzC,CAAC,iBAAkB,UACnB,CAAC,WAAY,QACb,CAAC,UAAW,SACZ,CAAC,cAAe,QAChB,CAAC,iCAAkC,YACnC,CAAC,UAAW,QACZ,CAAC,YAAa,UAIP,qBAAoC,CAAC,oBAAqB,QAG1D,yBAA0C,CACjD,CAAC,KAAM,SACP,CAAC,KAAM,SACP,CAAC,KAAM,SACP,CAAC,KAAM,SACP,CAAC,IAAK,SACN,CAAC,IAAK,UAGC,mBAAkC,CAAC,KAAM,QAGzC,mBAAoC,CAC3C,CAAC,KAAM,QACP,CAAC,KAAM,QACP,CAAC,gCAAiC,UAClC,CAAC,4CAA6C,WAIhD,mBAAgB,GAAI,GACpB,mBAAgB,KAAK,cAAc,cAAc,IAC/C,AAAC,GAAM,GAAI,QAAO,EAAG,MAEvB,mBAAgB,KAAK,cAAc,cAAc,IAC/C,AAAC,GAAM,GAAI,QAAO,EAAG,MAWvB,SAAS,EAAc,EAA+B,GAAiB,CACrE,OAAS,KAAS,MAAK,gBAAiB,CACtC,GAAI,CAAC,EAAQ,GAAgB,CAAC,GAAG,GACjC,EAAO,EAAK,QAAQ,EAAQ,GAG9B,OAAS,KAAQ,MAAK,YAAa,CACjC,GAAI,CAAC,EAAQ,GAAgB,CAAC,GAAG,GACjC,EAAO,EAAK,QAAQ,EAAQ,GAI9B,GAAI,CAAC,EAAQ,GAAgB,CAAC,GAAG,KAAK,iBAItC,GAHA,EAAO,EAAK,QAAQ,EAAQ,GAGxB,EACF,OAAS,KAAS,MAAK,oBAAqB,CAC1C,GAAI,CAAC,EAAQ,GAAgB,CAAC,GAAG,GACjC,EAAO,EAAK,QAAQ,EAAQ,GAKhC,GAAI,CAAC,EAAQ,GAAgB,CAAC,GAAG,KAAK,eACtC,EAAO,EAAK,QAAQ,EAAQ,GAG5B,EAAO,IAAM,EAAO,IAEpB,OAAS,KAAS,MAAK,cAAe,CACpC,GAAI,CAAC,EAAQ,GAAgB,CAAC,GAAG,GACjC,EAAO,EAAK,QAAQ,EAAQ,GAG9B,OAAS,KAAU,MAAK,cACtB,EAAO,EAAK,QAAQ,EAAQ,WAG9B,OAAS,KAAU,MAAK,cACtB,EAAO,EAAK,QAAQ,EAAQ,WAG9B,MAAO,GAAK,OAAO,MAAM,OAG3B,cAAc,EAAkC,CAC9C,GAAI,GAAsB,KAAK,SAAS,GACpC,EAMJ,GAAI,EAAK,SAAS,MAAQ,EAAK,SAAS,MAAO,CAE7C,GAAI,GAAoB,CAAC,GAAG,EAAK,SAAS,gBAAgB,IACxD,AAAC,GAAU,EAAM,IAOnB,EAAS,EAAU,IAAI,AAAC,GACtB,CAAC,IAAK,KAAM,MAAM,QAAQ,KAAS,GAAK,EAAQ,OAAO,EAAG,GAAG,GAAK,OAGpE,GAAS,EAGX,MAAO,GAAa,EAAQ,GAG9B,eAAe,EAAW,CACxB,MAAO,GAAU,IAAI,AAAC,GAAM,KAAK,SAAS,KAG3C,oBAAoB,EAAW,CAC9B,OAAS,KAAK,GACZ,KAAM,MAAK,cAAc,KAK/B,OAAO,QAAU",
  "names": []
}
